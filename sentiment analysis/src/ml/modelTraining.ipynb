{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b0d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83384ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c758a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CleanData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef850e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Loves and misses her friend(s), not to mention...</td>\n",
       "      <td>love miss friend mention brother that mr kimmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@xstex aww i always miss the good parts on BB</td>\n",
       "      <td>xstex aww alway miss good part bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>@mackenziesmomma You know I do! Not only do I ...</td>\n",
       "      <td>mackenziesmomma know want see want copi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ang hirap mo ireject!  http://plurk.com/p/remdz</td>\n",
       "      <td>ang hirap mo ireject http plurk com p remdz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@cassiesporaa Haha he definitely does, yummmy.</td>\n",
       "      <td>cassiesporaa haha definit yummmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Did I mention that Selenium is now 1.0? Better...</td>\n",
       "      <td>mention selenium better get crack http seleniu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       4  Loves and misses her friend(s), not to mention...   \n",
       "1       0     @xstex aww i always miss the good parts on BB    \n",
       "2       4  @mackenziesmomma You know I do! Not only do I ...   \n",
       "3       0    ang hirap mo ireject!  http://plurk.com/p/remdz   \n",
       "4       4    @cassiesporaa Haha he definitely does, yummmy.    \n",
       "5       4  Did I mention that Selenium is now 1.0? Better...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0     love miss friend mention brother that mr kimmi  \n",
       "1                  xstex aww alway miss good part bb  \n",
       "2            mackenziesmomma know want see want copi  \n",
       "3        ang hirap mo ireject http plurk com p remdz  \n",
       "4                   cassiesporaa haha definit yummmi  \n",
       "5  mention selenium better get crack http seleniu...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "003888b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>0</td>\n",
       "      <td>Omg. Im going to be carless... NOOOO!</td>\n",
       "      <td>omg im go carless noooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>0</td>\n",
       "      <td>@smileychic4919 a hot fudge brownie sundae wou...</td>\n",
       "      <td>smileych hot fudg browni sunda would even bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>0</td>\n",
       "      <td>@MiszJuicyBaybee im guessin ya don't got passe...</td>\n",
       "      <td>miszjuicybaybe im guessin ya got pass disney r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>4</td>\n",
       "      <td>i'm holding back tears of happiness right now!...</td>\n",
       "      <td>hold back tear happi right want scrreeeaaammmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>0</td>\n",
       "      <td>got back from church i broke her foot when i c...</td>\n",
       "      <td>got back church broke foot caught holyghost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>0</td>\n",
       "      <td>Infamous got me on the point wre I want to bre...</td>\n",
       "      <td>infam got point wre want break control search ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text  \\\n",
       "39994       0             Omg. Im going to be carless... NOOOO!    \n",
       "39995       0  @smileychic4919 a hot fudge brownie sundae wou...   \n",
       "39996       0  @MiszJuicyBaybee im guessin ya don't got passe...   \n",
       "39997       4  i'm holding back tears of happiness right now!...   \n",
       "39998       0  got back from church i broke her foot when i c...   \n",
       "39999       0  Infamous got me on the point wre I want to bre...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "39994                            omg im go carless noooo  \n",
       "39995  smileych hot fudg browni sunda would even bett...  \n",
       "39996  miszjuicybaybe im guessin ya got pass disney r...  \n",
       "39997     hold back tear happi right want scrreeeaaammmm  \n",
       "39998        got back church broke foot caught holyghost  \n",
       "39999  infam got point wre want break control search ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f24fcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting text to numbers...\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X = df['cleaned_text'].values\n",
    "Y = df['target'].values\n",
    "\n",
    "\n",
    "print(\"Converting text to numbers...\")\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62da4309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Model Accuracy: 74.66%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "# 5. Train\n",
    "print(\"Training Model...\")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# 6. Result\n",
    "acc = accuracy_score(Y_test, model.predict(X_test))\n",
    "\n",
    "print(f\"Model Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b4658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1=accuracy_score(Y_train,model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fbb907b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353753828842908"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc91250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\VICTUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "port_stem = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: happy but bad enjoy\n",
      "4\n",
      "Sentiment: Positive ðŸ˜ƒ (Khushi/Tareef)\n"
     ]
    }
   ],
   "source": [
    "def stemming(content):\n",
    "  \n",
    "    cleaned_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "  \n",
    "    cleaned_content = cleaned_content.lower()\n",
    "   \n",
    "    cleaned_content = cleaned_content.split()\n",
    "\n",
    "    cleaned_content = [port_stem.stem(word) for word in cleaned_content if word not in stop_words]\n",
    "   \n",
    "    cleaned_content = ' '.join(cleaned_content)\n",
    "    return cleaned_content\n",
    "\n",
    "def predict_sentiment(input_text):\n",
    "    \n",
    "   \n",
    "    cleaned_text = stemming(input_text)\n",
    "    \n",
    "    \n",
    "    if cleaned_text == \"\":\n",
    "        return \"Error: Please enter a meaningful sentence in English.\"\n",
    "\n",
    "   \n",
    "    input_vector = vectorizer.transform([cleaned_text])\n",
    "    \n",
    " \n",
    "    prediction = model.predict(input_vector)\n",
    "    \n",
    "    print(prediction[0])\n",
    "   \n",
    "    if prediction[0] == 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Positive \"\n",
    "\n",
    "\n",
    "user_input = input(\"Enter a sentence to check sentiment: \")\n",
    "print(f\"Original: {user_input}\")\n",
    "print(f\"Sentiment: {predict_sentiment(user_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Badhai ho! ðŸ¥³\n",
      "Aapka Model 'trained_model.sav' aur Vectorizer 'vectorizer.pkl' naam se save ho gaya hai.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "filename = 'trained_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
